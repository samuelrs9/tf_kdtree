/**
 * 
 * @file test_kdtree.cpp
 * @author Thomas Grandits (thomas.grandits@icg.tugraz.at)
 * @brief Short test to see if the KD-Tree implementation works on the C++ side.
 *        This could also be used as a reference, if a simple C++ implementation is 
 *        needed without using Tensorflow.
 * @version 0.1
 * @date 2020-11-16
 * 
 * @copyright Copyright (c) 2020
 * 
 */
#include <random>
#include <iostream>
#include "kdtree.hpp"
#include "tf_kdtree.hpp"
 
const int nr_points = 1000;
const int dims = 2;
const int levels = 11;

const int nr_query_points = 10;
const point_i_knn_t knn = 20;
const int metric = 0;

typedef double test_T;

template <typename T, dim_t dims>
std::tuple<T*, point_i_t*, T*> copyData(const std::vector<T>& result_dists, const std::vector<point_i_t>& result_idx, 
    const std::vector<std::array<T, dims>>& points_query);

template <typename T>
std::tuple<T*, point_i_t*> copyDataBackToHost(const T* result_dists, const point_i_t* result_idx, const size_t nr_query, const uint32_t nr_nns_searches);

int main()
{
    std::random_device rd;  //Will be used to obtain a seed for the random number engine
    std::mt19937 gen(0); //Standard mersenne_twister_engine seeded with rd()
    std::normal_distribution<test_T> distrib(0, 5);
    std::vector<test_T> point_cloud;
 
    for (int n=0; n<nr_points*dims; ++n)
        //Use `distrib` to transform the random unsigned int generated by gen into an int in [1, 6]
       point_cloud.push_back(distrib(gen));
    
    std::cout << "Generated points..." << std::endl;

    auto partition_info = createKDTree<test_T, dims>(point_cloud.data(), nr_points, levels);
    assert(partition_info.levels == levels);
    //fillKDTreeParents<test_T, dims>(main_partition);

    std::vector<test_T> query_points;
    for (int n=0; n<nr_query_points*dims; ++n)
        //Use `distrib` to transform the random unsigned int generated by gen into an int in [1, 6]
       query_points.push_back(distrib(gen));

    std::vector<test_T> result_dists(nr_query_points*knn);
    std::vector<point_i_t> result_idx(nr_query_points*knn);
    KDTreeKNNSearch<test_T, test_T, dims>(partition_info, nr_query_points, 
        reinterpret_cast<std::array<test_T, dims>*>(query_points.data()), 
        result_dists.data(), result_idx.data(), knn, metric);

    //GPU Test
    PartitionInfoDevice<test_T, dims>* partition_info_d = copyPartitionToGPU<test_T, dims>(partition_info);
    const auto tmp = copyData<test_T, dims>(result_dists, result_idx, std::vector<std::array<test_T, dims>>(reinterpret_cast<std::array<test_T, dims>*>(query_points.data()), 
                                                                reinterpret_cast<std::array<test_T, dims>*>(query_points.data()) + query_points.size() / dims));
    test_T* result_dists_d = std::get<0>(tmp);
    point_i_t* result_idx_d = std::get<1>(tmp);
    test_T* query_points_d  = std::get<2>(tmp);

    KDTreeKNNGPUSearch<test_T, test_T, dims>(partition_info_d, nr_query_points, 
        reinterpret_cast<std::array<test_T, dims>*>(query_points_d), result_dists_d, result_idx_d, knn, 0);

    auto result_gpu = copyDataBackToHost(result_dists_d, result_idx_d, nr_query_points, knn);
    const auto result_dists_gpu = std::get<0>(result_gpu);
    const auto result_idx_gpu = std::get<1>(result_gpu);

    for(size_t i = 0; i < result_dists.size(); i++)
    {
        std::cout << result_dists[i] << ", " << result_dists_gpu[i] << " / " << result_idx[i] << ", " << result_idx_gpu[i] << std::endl;
    }

    if(!std::equal(result_idx_gpu, result_idx_gpu + nr_query_points*knn, result_idx.begin()))
        throw std::runtime_error("Error when comparing KD-Tree solution against the reference");

    if(!std::equal(result_dists_gpu, result_dists_gpu + nr_query_points*knn, result_dists.begin(), [](const double lhs, const double rhs){return std::abs<double>(lhs - rhs) < 1e-7;}))
        throw std::runtime_error("Error when comparing KD-Tree solution against the reference");

    freePartitionFromGPU(partition_info_d);
    std::cout << "Success" << std::endl;
    return 0;
}